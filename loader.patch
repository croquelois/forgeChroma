diff --git a/backend/loader.py b/backend/loader.py
index e824f6b..532f12a 100644
--- a/backend/loader.py
+++ b/backend/loader.py
@@ -22,9 +22,10 @@ from backend.diffusion_engine.sd20 import StableDiffusion2
 from backend.diffusion_engine.sdxl import StableDiffusionXL, StableDiffusionXLRefiner
 from backend.diffusion_engine.sd35 import StableDiffusion3
 from backend.diffusion_engine.flux import Flux
+from backend.diffusion_engine.chroma import Chroma
 
 
-possible_models = [StableDiffusion, StableDiffusion2, StableDiffusionXLRefiner, StableDiffusionXL, StableDiffusion3, Flux]
+possible_models = [StableDiffusion, StableDiffusion2, StableDiffusionXLRefiner, StableDiffusionXL, StableDiffusion3, Flux, Chroma]
 
 
 logging.getLogger("diffusers").setLevel(logging.ERROR)
@@ -108,7 +109,7 @@ def load_huggingface_component(guess, component_name, lib_name, cls_name, repo_p
             load_state_dict(model, state_dict, log_name=cls_name, ignore_errors=['transformer.encoder.embed_tokens.weight', 'logit_scale'])
 
             return model
-        if cls_name in ['UNet2DConditionModel', 'FluxTransformer2DModel', 'SD3Transformer2DModel']:
+        if cls_name in ['UNet2DConditionModel', 'FluxTransformer2DModel', 'SD3Transformer2DModel', 'ChromaTransformer2DModel']:
             assert isinstance(state_dict, dict) and len(state_dict) > 16, 'You do not have model state dict!'
 
             model_loader = None
@@ -117,6 +118,9 @@ def load_huggingface_component(guess, component_name, lib_name, cls_name, repo_p
             elif cls_name == 'FluxTransformer2DModel':
                 from backend.nn.flux import IntegratedFluxTransformer2DModel
                 model_loader = lambda c: IntegratedFluxTransformer2DModel(**c)
+            elif cls_name == 'ChromaTransformer2DModel':
+                from backend.nn.chroma import IntegratedChromaTransformer2DModel
+                model_loader = lambda c: IntegratedChromaTransformer2DModel(**c)
             elif cls_name == 'SD3Transformer2DModel':
                 from backend.nn.mmditx import MMDiTX
                 model_loader = lambda c: MMDiTX(**c)
@@ -216,6 +220,7 @@ def replace_state_dict(sd, asd, guess):
 
     ##  identify model type
     flux_test_key = "model.diffusion_model.double_blocks.0.img_attn.norm.key_norm.scale"
+    chroma_test_key = "distilled_guidance_layer.layers.0.in_layer.bias";
     sd3_test_key = "model.diffusion_model.final_layer.adaLN_modulation.1.bias"
     legacy_test_key = "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight"
 
@@ -231,7 +236,10 @@ def replace_state_dict(sd, asd, guess):
             case 2048:
                 model_type = "sdxl"
     elif flux_test_key in sd:
-        model_type = "flux"
+        if chroma_test_key in sd:
+            model_type = "chroma"
+        else:
+            model_type = "flux"
     elif sd3_test_key in sd:
         model_type = "sd3"
 
@@ -243,6 +251,7 @@ def replace_state_dict(sd, asd, guess):
         "xlrf": None,
         "sdxl": "conditioner.embedders.0.transformer.",
         "flux": "text_encoders.clip_l.transformer.",
+        "chroma": "text_encoders.clip_l.transformer.",
         "sd3" : "text_encoders.clip_l.transformer.",
     }
     ##  prefixes used by various model types for CLIP-G
@@ -253,6 +262,7 @@ def replace_state_dict(sd, asd, guess):
         "xlrf": "conditioner.embedders.0.model.transformer.",
         "sdxl": "conditioner.embedders.1.model.transformer.",
         "flux": None,
+        "chroma": None,
         "sd3" : "text_encoders.clip_g.transformer.",
     }
     ##  prefixes used by various model types for CLIP-H
@@ -263,6 +273,7 @@ def replace_state_dict(sd, asd, guess):
         "xlrf": None,
         "sdxl": None,
         "flux": None,
+        "chroma": None,
         "sd3" : None,
     }
 
@@ -485,7 +496,12 @@ def forge_loader(sd, additional_state_dicts=None):
         state_dicts, estimated_config = split_state_dict(sd, additional_state_dicts=additional_state_dicts)
     except:
         raise ValueError('Failed to recognize model type!')
-    
+
+    if estimated_config.huggingface_repo == "black-forest-labs/FLUX.1-schnell"  \
+        and "transformer" in state_dicts \
+        and "distilled_guidance_layer.layers.0.in_layer.bias" in state_dicts["transformer"]:
+        estimated_config.huggingface_repo = "Chroma"
+        print("load Chroma model")
     repo_name = estimated_config.huggingface_repo
 
     local_path = os.path.join(dir_path, 'huggingface', repo_name)
